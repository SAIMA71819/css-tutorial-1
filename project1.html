<!-- #OpenAI. (2025). ChatGPT (Feb 3 version) [Large language model]. OpenAI. https://openai.com
#My target audience is young adults aged between 19 and 30, who are likely tech-savvy and enjoy engaging with content that's visually appealing and easy to navigate.
 I have chosen a sleek and vibrant color scheme, pairing light blue with deep blue to create a striking contrast. These colors not only grab attention but also offer a calm and focused researching experience. 
 The design focuses on clear, structured sections for headers (H1, H2, H3), helping to break up the content and make it easy for readers to scan through the page quickly.
For the typography, I have kept the font sizes smaller for the body text while making the headers and titles stand out. This design choice helps establish a visual hierarchy, making it clear where the key information is while maintaining a clean and modern look. 
My target is to create a fresh and vibrant look that can attract younger audiences.-->

<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Project 1</title>
    <link rel="stylesheet" href="project1.css"/>
</head>
<body>
    <header>
        <h1>AI Incidents Reported</h1>
        <p>This page provides an overview of AI incidents</p>
        <nav id="main-nav">
            <ul>
                <li><a href="#incident-1">Tesla Autopilot</a></li>
                <li><a href="#incident-2">Scarlett Johansson Voice Imitation</a></li>
                <li><a href="#incident-3">Facebook's translation glitch</a></li>
                <li><a href="#incident-4">Microsoft’s algorithm selected photo of the wrong mixed-race person</a></li>
            </ul>
        </nav>
    </header>
    <main>
        <section id="incident-1">
            <h2>Tesla Autopilot Incidents</h2>
            <p>A collection of Tesla autopilot-involved crashes.</p>
             
            <h3>Incident Details</h3>
            <p><strong>Date:</strong> 2016-06-30</p>
            <p>It was reported that a number of accidents occurred due to Tesla's autopilot. Multiple unrelated car accidents resulted in varying levels of harm while Tesla's autopilot was in use. As a result, there have also been reports of deaths.</p>
            
            <h3>Impact</h3>
            <p>People had started to become comfortable with the idea of autopilot. However, after these incidents, it caused everyone to second-guess the autopilot system. This led to shock, fear, and upset among the public.</p>
            
            <h3>References</h3>
            <a href="https://www.theguardian.com/technology/2016/jun/30/tesla-autopilot-death-self-driving-car-elon-musk ">Click here to read more about the story.</a>

            
        </section>

        <section id="incident-2">
            <h2>Scarlett Johansson Voice Imitation</h2>
            <p>Scarlett johansson alleges openai's sky imitates her voice without licensing.</p>
            
            <h3>Incident Details</h3>
            <p><strong>Date:</strong> 2024-05-20</p>
            <p>It was reported that Scarlett Johansson, a famous Hollywood actress, was deeply upset when she heard the voice assistant. OpenAI unveiled a voice assistant with a voice resembling Johansson's, despite her refusal to license her voice. Johansson claimed the assistant, 'Sky,' sounded 'eerily similar' to her voice, leading her to seek legal action. OpenAI suspended Sky, asserting that the voice came from a different actress. However, Johansson proceeded to file a lawsuit against the company, as she felt it was disrespectful and taken without her consent.</p>
            
            <h3>Impact</h3>
            <p>Scarlett Johansson was deeply upset and shocked after discovering that OpenAI had imitated her voice without her consent. She felt that the situation was highly disrespectful and an invasion of her privacy. As a result, she decided to take legal action by filing a lawsuit against the company.</p>
            
            <h3>References</h3>
            <a href="https://www.usatoday.com/story/tech/news/2024/05/20/scarlett-johansson-chatgpt-openai-voice-sky/73778960007/">Click here to read more about the story.</a>

            
        </section>

        <section id="incident-3">
            <h2>Facebook translates 'good morning' into 'attack them', leading to arrest</h2>
            <p>Facebook's translation glitch turns 'Good morning' into 'Attack them,' causing confusion and concern.</p>
            
            <h3>Incident Details</h3>
            <p><strong>Date:</strong>2017-10-17</p>
            <p>The incident was reported in 2017 and occurred under a Facebook comment. A Palestinian man posted a picture of himself leaning against a bulldozer with the caption “يصبحهم” or “yusbihuhum,” which translates to “Good morning.” However, Facebook’s automatic language translation software mistakenly translated it into Hebrew as “Hurt them,” leading to his arrest in Beitar Illit, Israel. This unfortunate mistranslation caused unnecessary trouble for the man, as his innocent message was misinterpreted, turning a harmless situation into a serious misunderstanding.
            </p>
            
            <h3>Impact</h3>
            <p>A Palestinian man faced embarrassment when Facebook mistakenly translated 'Good morning' as 'Attack them.' Facebook later apologized for the misunderstanding.</p>
            
            <h3>References</h3>
            <a href="https://www.theguardian.com/technology/2017/oct/24/facebook-palestine-israel-translates-good-morning-attack-them-arrest">Click here to read more about the story.</a>

            
        </section>

        <section id="incident-4">
            <h2>Microsoft’s algorithm allegedly selected photo of the wrong mixed-race person featured in a news story</h2>
            <p>Microsoft is facing criticism after an AI system on MSN.com used the wrong photo of a mixed-race person in a news story. The mistake followed layoffs of human journalists, raising concerns about AI’s reliability in news curation.</p>
            
            <h3>Incident Details</h3>
            <p><strong>Date:</strong> 2020-06-06	</p>
            <p>A news story published on MSN.com mistakenly featured a photo of the wrong mixed-race person, allegedly chosen by an algorithm. The error happened when Microsoft's AI-powered news system used an image of the wrong Little Mix singer in an article about the group. This mistake sparked criticism, with many questioning whether AI can handle editorial decisions, especially when it comes to sensitive topics like race and identity. As a result, Microsoft laid off several journalists and editorial workers, replacing them with AI systems—a move that further fueled debates about the reliability and ethics of automated news curation.</p>
            
            <h3>Impact</h3>
            <p>The incident fueled criticism over AI’s role in news curation, especially after Microsoft’s layoffs of journalists. It raised concerns about misinformation and the loss of accountability when humans are replaced by algorithms.</p>
            
            <h3>References</h3>
            <a href="https://www.theguardian.com/technology/2020/jun/09/microsofts-robot-journalist-confused-by-mixed-race-little-mix-singers">Click here to read more about the story.</a>
                
        </section>
    </main>
</body>
</html>
